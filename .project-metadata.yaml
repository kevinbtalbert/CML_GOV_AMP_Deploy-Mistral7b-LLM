name: Mistral-7B Standalone Model Deployment
description: This AMP deploys Mistral-7b model as a CML model endpoint, callable via an API. Model is hosted within CML and requires GPU node with 16GB memory and 4 cores minimum.
author: Cloudera
date: "2025-1-9"
specification_version: 1.0
prototype_version: 1.0

environment_variables:
  HF_ACCESS_TOKEN:
    default: ""
    description: "HF Access Token to use Mistral 7B model"
    required: true
  PATH:
    default: "${PATH}:$HOME/cuda/bin:$HOME/cuda/nvvm"
    description: "Leave this value as is"
    required: true
  LD_LIBRARY_PATH:
    default: "${LD_LIBRARY_PATH}:$HOME/cuda/lib64:$HOME/cuda/nvvm/lib64:$HOME/cuda/nvvm"
    description: "Leave this value as is"
    required: true
  CUDA_HOME:
    default: "$HOME/cuda"
    description: "Leave this value as is"
    required: true

runtimes: 
  - editor: PBJ Workbench
    kernel: Python 3.9
    edition: GovCloud
  
tasks:
  - type: run_session
    name: Deploy NVIDIA Toolkit
    script: install-drivers.py
    short_summary: Install Dependencies
    kernel: python3
    cpu: 2
    memory: 16
    gpu: 1

  - type: create_model
    name: Mistral-7b
    entity_label: mistral-7b
    description: Mistral-7b model hosted in CML. 
    short_summary: Mistral-7b
    default_resources:
      cpu: 4
      memory: 16
      gpu: 1
    default_replication_policy:
      type: fixed
      num_replicas: 1
  
  - type: build_model
    name: Build Mistral 7B model
    entity_label: mistral-7b
    comment: First build by the AMP
    examples:
      - request:
          prompt: What is Cloudera?
          temperature: 0
          max_new_tokens: 50
          repetition_penalty: 0.5

    target_file_path: Launch_model.py
    target_function_name: api_wrapper

  - type: deploy_model
    entity_label: mistral-7b